[core]
no_lock = True

[worker]
keep_alive = False
ping_interval = 20
wait_interval = 20
max_reschedules = 0

[DEFAULT]
name = MC_Test

# grid storage protocol and path usable from submitting machine and worker nodes of cluster
# job in- and output will be stored in $wlcg_path under subdirectory of analysis $name
wlcg_path = srm://cmssrm-kit.gridka.de:8443/srm/managerv2?SFN=/pnfs/gridka.de/cms/disk-only/store/user/mhorzela/HerwigMC
xrootd_path =  root://cmsxrootd-redirectors.gridka.de//store/user/mhorzela/NP_Corrections/MC_Production

# default htcondor job submission configuration (modifiable for each task)
htcondor_accounting_group = cms.jet
htcondor_remote_job = True
# TODO: Set your user proxy to your personal one 
htcondor_user_proxy = /tmp/x509up_u12249
htcondor_request_cpus = 1
# for all cores in total
htcondor_universe = docker
htcondor_docker_image = mschnepf/slc7-condocker
# create log files in htcondor jobs
transfer_logs = True
# set local scheduler
local_scheduler = True
# set tolerance for workflow success with failed branches
tolerance = 0
# submit only missing htcondor workflow branches (should always be true)
only_missing = True

# bootstrap file to be sourced at beginning of htcondor jobs (relative PATH to framework.py)
bootstrap_file = setup_herwig.sh
# 5% fault tolerance
tolerance = 0.05
acceptance = 0.95

# Herwig input file and settings
input_file_name = LHC-ZJetMerging # the name of the input file in the inputfiles directory w/o file extension
mc_setting = withNP # currently only for grid storage path
integration_maxjobs = 1840 # number of integration jobs



[HerwigBuild]


[HerwigIntegrate]
#HTCondor
htcondor_walltime = 43200
htcondor_request_memory = 1500
htcondor_requirements = TARGET.ProvidesCPU
htcondor_request_disk = 12000000


[HerwigMerge]


[HerwigRun]
# run specific settings
start_seed = 100
number_of_jobs = 600
events_per_job = 1000
# HTCondor
htcondor_walltime = 43200
htcondor_request_memory = 1500
htcondor_requirements = TARGET.ProvidesCPU
htcondor_request_disk = 12000000
